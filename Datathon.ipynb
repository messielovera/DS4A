{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ruta='C:/Users/William Romero/Downloads/DS4A/Dataset/Dataset/'\n",
    "\n",
    "#Lectura del archivo Geographic\n",
    "geometry = pd.read_csv(ruta+'geographic.csv')\n",
    "\n",
    "#Creación de Data Frame que va a almacenar el código del barrio con una de sus latitudes y longitudes relacionadas a un punto\n",
    "\n",
    "df = pd.DataFrame({'Code':[],'Lat':[],'Lon':[]})\n",
    "\n",
    "fila = 0\n",
    "#for barrio in geometry:\n",
    "barrio=\"BK88\"\n",
    "while (fila < len(geometry) and not (np.isnan(geometry[barrio][fila]))):\n",
    "    longitud = geometry[barrio][fila]\n",
    "    latitud = geometry[barrio][fila+1]\n",
    "    #if not (np.isnan(latitud) | np.isnan(longitud)): \n",
    "        #Si existe al menos un nan significa que no es un punto\n",
    "    df2 = pd.DataFrame({'Code':[barrio],'latitude':[latitud],'longitude':[longitud]})\n",
    "    df = df.append(df2, ignore_index=True)\n",
    "    fila += 2\n",
    "df.head()\n",
    "lista = []\n",
    "latitudes=df['latitude'].tolist()\n",
    "longitudes=df['longitude'].tolist()\n",
    "longitudes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "lat_point_list = latitudes\n",
    "lon_point_list = longitudes\n",
    "\n",
    "polygon_geom = Polygon(zip(lon_point_list,lat_point_list))\n",
    "crs = {'init': 'epsg:4326'}\n",
    "polygon = gpd.GeoDataFrame(index=[0], crs=crs, geometry=[polygon_geom])       \n",
    "print(polygon.geometry)\n",
    "\n",
    "polygon.to_file(filename='polygon.geojson', driver='GeoJSON')\n",
    "polygon.to_file(filename='polygon.shp', driver=\"ESRI Shapefile\")\n",
    "\n",
    "import folium\n",
    "m = folium.Map([40.63128, -73.97605], zoom_start=12, tiles='cartodbpositron')\n",
    "folium.GeoJson(polygon).add_to(m)\n",
    "folium.LatLngPopup().add_to(m)\n",
    "m.save(\"mapa.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_geodf(df, lat_col_name='latitude', lon_col_name='longitude'):\n",
    "    \"\"\"\n",
    "    Take a dataframe with latitude and longitude columns, and turn\n",
    "    it into a geopandas df.\n",
    "    \"\"\"\n",
    "    from geopandas import GeoDataFrame\n",
    "    from geopandas import points_from_xy\n",
    "    df = df.copy()\n",
    "    lat = df['latitude']\n",
    "    lon = df['longitude']\n",
    "    return GeoDataFrame(df, geometry=points_from_xy(lon, lat))\n",
    "\n",
    "dfGeoDataFrame=make_geodf(df)\n",
    "dfGeoDataFrame.head()\n",
    "type(dfGeoDataFrame['geometry'])\n",
    "\n",
    "#arreglopuntos=[];\n",
    "#arreglopuntos=dfGeoDataFrame['geometry']\n",
    "#arreglopuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Lon, df.Lat))\n",
    "\n",
    "#world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "#world = gpd.read_file(gpd.datasets.get_path('nybb'))\n",
    "world = gpd.read_file(ruta+'NYC.shp')\n",
    "\n",
    "ax = world.plot(color='white', edgecolor='black')\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "#gdf.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Cargue archivos UBER\n",
    "uber_2014 = pd.read_csv(ruta+'uber_trips_2014.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "uber_2015 = pd.read_csv(ruta+'uber_trips_2015.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "#Cargue archivo Taxi\n",
    "taxi = pd.read_csv(ruta+'yellow_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "#Cargue archivo Green Taxi\n",
    "#green = pd.read_csv(ruta+'green_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "#Cargue archivo MTA\n",
    "#train = pd.read_csv(ruta+'mta_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "\n",
    "uber = uber_2014.append(uber_2015, sort=False, ignore_index=True)\n",
    "uber_copy = uber.copy()\n",
    "uber_copy['pickup_datetime'] = pd.to_datetime(uber_copy['pickup_datetime'])\n",
    "uber_copy['date'] = uber_copy['pickup_datetime'].dt.date\n",
    "uber_copy['day'] = uber_copy['pickup_datetime'].dt.day\n",
    "uber_copy['month'] = uber_copy['pickup_datetime'].dt.month\n",
    "uber_copy['year'] = uber_copy['pickup_datetime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uber_conteo = uber_copy.groupby(['year','month','day']).count()[['pickup_datetime']]\n",
    "uber_conteo.rename(columns={'pickup_datetime':'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte nueva 12/10/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#Mapa Original (sin marcar el barrio)(12/10/2019)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import folium\n",
    "import branca\n",
    "mi_mapa = folium.Map(location=(40.63,-73.97), tiles=\"cartodbpositron\", zoom_start=12)\n",
    "\n",
    "\n",
    "#Lectura del archivo Geographic\n",
    "geometry = pd.read_csv(ruta + 'geographic.csv')\n",
    "\n",
    "#Creación de Data Frame que va a almacenar el código del barrio con una de sus latitudes y longitudes relacionadas a un punto\n",
    "df = pd.DataFrame({'Lat':[],'Lon':[]})\n",
    "#for barrio in geometry:\n",
    "barrio = \"BK88\" #si se desea hacer para todos los barrios, quitar BK88, des-comentar la linea anterior e identar de manera acorde\n",
    "fila = int(\"0\")\n",
    "while fila < len(geometry) and not (np.isnan(geometry[barrio][fila])):\n",
    "    folium.CircleMarker(\n",
    "        [geometry[barrio][fila+1],geometry[barrio][fila]],\n",
    "        radius=5,\n",
    "        popup = ('hello world'),\n",
    "        color='b',\n",
    "        threshold_scale=[0,1,2,3],\n",
    "        fill=True,\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(mi_mapa)\n",
    "    fila += 2\n",
    "mi_mapa\n",
    "#mi_mapa.save(\"MAPA.html\") #Línea para guardar el archivo HTML del mapa en carpeta raiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#Cargue de información + modificación de transporte + gráfica (falta Train) (12/10/2019)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Cargue archivos UBER\n",
    "uber_2014 = pd.read_csv(ruta + 'uber_trips_2014.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "uber_2015 = pd.read_csv(ruta + 'uber_trips_2015.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "\n",
    "#Procesos de Uber consolidado\n",
    "uber = uber_2014.append(uber_2015, sort=False, ignore_index=True)\n",
    "uber_copy = uber.copy()\n",
    "uber_copy['pickup_datetime'] = pd.to_datetime(uber_copy['pickup_datetime'])\n",
    "\n",
    "#Cargue archivo Taxi\n",
    "taxi = pd.read_csv(ruta + 'yellow_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "\n",
    "#Procesos de Taxi\n",
    "taxi['pickup_datetime'] = pd.to_datetime(taxi['pickup_datetime'])\n",
    "\n",
    "#Cargue archivo Green Taxi\n",
    "green = pd.read_csv(ruta + 'green_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "\n",
    "#Procesos de Green Taxi\n",
    "green['pickup_datetime'] = pd.to_datetime(green['pickup_datetime'])\n",
    "\n",
    "uber_copy['date'] = uber_copy['pickup_datetime'].dt.date\n",
    "uber_copy_pivot = uber_copy.groupby(['date']).count()[['pickup_datetime']]\n",
    "uber_copy_pivot = uber_copy_pivot.reset_index()\n",
    "uber_copy_pivot['method'] = \"Uber\"\n",
    "\n",
    "taxi['date'] = taxi['pickup_datetime'].dt.date\n",
    "taxi_pivot = taxi.groupby(['date']).count()[['pickup_datetime']]\n",
    "taxi_pivot = taxi_pivot.reset_index()\n",
    "taxi_pivot['pickup_datetime'] = taxi_pivot['pickup_datetime']*20\n",
    "taxi_pivot['method'] = \"Taxi\"\n",
    "\n",
    "green['date'] = green['pickup_datetime'].dt.date\n",
    "green_pivot = green.groupby(['date']).count()[['pickup_datetime']]\n",
    "green_pivot = green_pivot.reset_index()\n",
    "green_pivot['pickup_datetime'] = green_pivot['pickup_datetime']*5\n",
    "green_pivot['method'] = \"Green Taxi\"\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "datos = uber_copy_pivot\n",
    "datos = datos.append(taxi_pivot, sort=False, ignore_index=True)\n",
    "datos = datos.append(green_pivot, sort=False, ignore_index=True)\n",
    "datos.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "ax = sns.lineplot(x=\"date\", y=\"pickup_datetime\", data=datos, hue=\"method\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#Este código solo carga el Train pero no está modificando los campos correctamente\n",
    "#Cargue archivo MTA\n",
    "train = pd.read_csv(ruta + 'mta_trips.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, dtype={'user_id': str})\n",
    "\n",
    "#Procesos de MTA\n",
    "print(\"inicio\")\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "print(\"datetime\")\n",
    "train['date'] = train['datetime'].dt.date\n",
    "print(\"date\")\n",
    "train_pivot = train.groupby(['date']).sum()[['new_entries']]\n",
    "train_pivot = train_pivot.reset_index()\n",
    "\n",
    "train_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#UBER 2014 and 2015 - Heatmap\n",
    "uber_pivot = uber_copy.groupby(['month','day']).count()[['pickup_datetime']]\n",
    "uber_pivot.rename(columns={'pickup_datetime':'count'}, inplace=True)\n",
    "uber_pivot = uber_pivot.reset_index()\n",
    "uber_pivot = uber_pivot.pivot('month','day','count')\n",
    "uber_pivot.fillna(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "sns.heatmap(uber_pivot, linewidths=.5, ax=ax, annot=True, fmt='.1f')\n",
    "ax.set_title('Heatmap Uber - 2014 y 2015');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#Heatmap para 2014\n",
    "uber_2014['pickup_datetime'] = pd.to_datetime(uber_2014['pickup_datetime'])\n",
    "uber_2014['date'] = uber_2014['pickup_datetime'].dt.date\n",
    "uber_2014['day'] = uber_2014['pickup_datetime'].dt.day\n",
    "uber_2014['month'] = uber_2014['pickup_datetime'].dt.month\n",
    "uber_2014['year'] = uber_2014['pickup_datetime'].dt.year\n",
    "uber_pivot = uber_2014.groupby(['month','day']).count()[['pickup_datetime']]\n",
    "uber_pivot.rename(columns={'pickup_datetime':'count'}, inplace=True)\n",
    "uber_pivot = uber_pivot.reset_index()\n",
    "uber_pivot = uber_pivot.pivot('month','day','count')\n",
    "uber_pivot.fillna(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "sns.heatmap(uber_pivot, linewidths=.5, ax=ax)\n",
    "ax.set_title('Heatmap Uber - 2014');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Author: alovera\n",
    "#Heatmap para 2015\n",
    "uber_2015['pickup_datetime'] = pd.to_datetime(uber_2015['pickup_datetime'])\n",
    "uber_2015['date'] = uber_2015['pickup_datetime'].dt.date\n",
    "uber_2015['day'] = uber_2015['pickup_datetime'].dt.day\n",
    "uber_2015['month'] = uber_2015['pickup_datetime'].dt.month\n",
    "uber_2015['year'] = uber_2015['pickup_datetime'].dt.year\n",
    "uber_pivot = uber_2015.groupby(['month','day']).count()[['pickup_datetime']]\n",
    "uber_pivot.rename(columns={'pickup_datetime':'count'}, inplace=True)\n",
    "uber_pivot = uber_pivot.reset_index()\n",
    "uber_pivot = uber_pivot.pivot('month','day','count')\n",
    "uber_pivot.fillna(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "sns.heatmap(uber_pivot, linewidths=.5, ax=ax)\n",
    "ax.set_title('Heatmap Uber - 2015');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
